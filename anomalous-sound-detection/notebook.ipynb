{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ef0cbf",
   "metadata": {
    "_cell_guid": "21b523fd-bf2b-45b8-aef0-299d3e54c6da",
    "_uuid": "22165675-39fd-411a-9273-66fba58fa343",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:05.394984Z",
     "iopub.status.busy": "2023-05-30T13:38:05.394377Z",
     "iopub.status.idle": "2023-05-30T13:38:09.021674Z",
     "shell.execute_reply": "2023-05-30T13:38:09.020750Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.636331,
     "end_time": "2023-05-30T13:38:09.024154",
     "exception": false,
     "start_time": "2023-05-30T13:38:05.387823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchaudio.backend.soundfile_backend import load\n",
    "from torch.utils.data import Dataset,DataLoader, ConcatDataset\n",
    "from torchaudio.transforms import MelSpectrogram, Spectrogram\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights, resnet50, ResNet50_Weights,  resnet18, ResNet18_Weights\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch import flatten\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8bc484",
   "metadata": {
    "_cell_guid": "e157c994-7cc2-4f8e-bc8f-ca684385d875",
    "_uuid": "33e58816-71b0-45ad-8bec-cfcb40435ed3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:09.035814Z",
     "iopub.status.busy": "2023-05-30T13:38:09.035328Z",
     "iopub.status.idle": "2023-05-30T13:38:09.040349Z",
     "shell.execute_reply": "2023-05-30T13:38:09.039435Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013224,
     "end_time": "2023-05-30T13:38:09.042737",
     "exception": false,
     "start_time": "2023-05-30T13:38:09.029513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'num_classes': 6,\n",
    "        'batch_size': 4,\n",
    "        'epochs': 9,\n",
    "        'win_len': 626, \n",
    "        'mel_bins': 128, \n",
    "        'hop_len': 313,\n",
    "        'n_fft' : 626,\n",
    "        'use_arcface': False, \n",
    "        'm': 0.5, \n",
    "        's': 30, \n",
    "        'sub': 1\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80354289",
   "metadata": {
    "_cell_guid": "79a43c55-ea60-4da5-815d-613a6e65909e",
    "_uuid": "5e79faeb-c9f5-4a7e-8e80-560f6d04fd2d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:09.054318Z",
     "iopub.status.busy": "2023-05-30T13:38:09.054038Z",
     "iopub.status.idle": "2023-05-30T13:38:09.064541Z",
     "shell.execute_reply": "2023-05-30T13:38:09.063725Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018231,
     "end_time": "2023-05-30T13:38:09.066483",
     "exception": false,
     "start_time": "2023-05-30T13:38:09.048252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class AudioDataset(Dataset):\\n    def __init__(self, params, dev_path, eval_path=None, mel_dev_path=None, mel_eval_path=None, transform=None, sr=16000):\\n        self.dev_path = dev_path\\n        self.eval_path = eval_path\\n        self.mel_dev_path = mel_dev_path\\n        self.mel_eval_path = mel_eval_path\\n        self.dev_files = os.listdir(dev_path)\\n        self.eval_files = os.listdir(eval_path) if eval_path else None\\n        self.dev_len = len(self.dev_files)\\n        self.eval_len = len(self.eval_files) if self.eval_files else 0\\n        self.mel_spectrogram = MelSpectrogram(sample_rate=sr, n_fft=params[\\'n_fft\\'], hop_length=params[\\'hop_len\\'], power=2.0)\\n        self.params = params\\n\\n    def __len__(self):\\n        return self.dev_len + self.eval_len\\n\\n    def __getitem__(self, idx):\\n        if idx < self.dev_len:\\n            dataset_path = self.dev_path\\n            mel_dataset_path = self.mel_dev_path\\n            files = self.dev_files\\n        elif 0 < idx - self.dev_len < self.eval_len:\\n            dataset_path = self.eval_path\\n            mel_dataset_path = self.mel_eval_path\\n            files = self.eval_files\\n            idx -= self.dev_len\\n        else:\\n            raise IndexError(f\"list index out of range: len={self.dev_len}, eval is not given\")\\n        \\n        filename = files[idx]\\n        machine_id = int(filename[11:12])\\n        label = filename.split(\\'_\\')[0]\\n        label = 0 if label == \"normal\" or label == \"id\" else 1\\n        target = nn.functional.one_hot(torch.tensor(machine_id), params[\"num_classes\"])\\n        audio, sr = load(dataset_path + \\'/\\' + filename)\\n        \\n        if mel_dataset_path is None:\\n            mel_spectr = self.mel_spectrogram(audio)\\n        else:\\n            mel_spectr = torch.load(mel_dataset_path + \\'/\\' + filename[:-4] + \\'.t\\')\\n        \\n        return audio, mel_spectr, target.float(), torch.FloatTensor([label])'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class AudioDataset(Dataset):\n",
    "    def __init__(self, params, dev_path, eval_path=None, mel_dev_path=None, mel_eval_path=None, transform=None, sr=16000):\n",
    "        self.dev_path = dev_path\n",
    "        self.eval_path = eval_path\n",
    "        self.mel_dev_path = mel_dev_path\n",
    "        self.mel_eval_path = mel_eval_path\n",
    "        self.dev_files = os.listdir(dev_path)\n",
    "        self.eval_files = os.listdir(eval_path) if eval_path else None\n",
    "        self.dev_len = len(self.dev_files)\n",
    "        self.eval_len = len(self.eval_files) if self.eval_files else 0\n",
    "        self.mel_spectrogram = MelSpectrogram(sample_rate=sr, n_fft=params['n_fft'], hop_length=params['hop_len'], power=2.0)\n",
    "        self.params = params\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dev_len + self.eval_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.dev_len:\n",
    "            dataset_path = self.dev_path\n",
    "            mel_dataset_path = self.mel_dev_path\n",
    "            files = self.dev_files\n",
    "        elif 0 < idx - self.dev_len < self.eval_len:\n",
    "            dataset_path = self.eval_path\n",
    "            mel_dataset_path = self.mel_eval_path\n",
    "            files = self.eval_files\n",
    "            idx -= self.dev_len\n",
    "        else:\n",
    "            raise IndexError(f\"list index out of range: len={self.dev_len}, eval is not given\")\n",
    "        \n",
    "        filename = files[idx]\n",
    "        machine_id = int(filename[11:12])\n",
    "        label = filename.split('_')[0]\n",
    "        label = 0 if label == \"normal\" or label == \"id\" else 1\n",
    "        target = nn.functional.one_hot(torch.tensor(machine_id), params[\"num_classes\"])\n",
    "        audio, sr = load(dataset_path + '/' + filename)\n",
    "        \n",
    "        if mel_dataset_path is None:\n",
    "            mel_spectr = self.mel_spectrogram(audio)\n",
    "        else:\n",
    "            mel_spectr = torch.load(mel_dataset_path + '/' + filename[:-4] + '.t')\n",
    "        \n",
    "        return audio, mel_spectr, target.float(), torch.FloatTensor([label])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af976e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:09.077556Z",
     "iopub.status.busy": "2023-05-30T13:38:09.077300Z",
     "iopub.status.idle": "2023-05-30T13:38:09.086705Z",
     "shell.execute_reply": "2023-05-30T13:38:09.085827Z"
    },
    "papermill": {
     "duration": 0.017502,
     "end_time": "2023-05-30T13:38:09.088890",
     "exception": false,
     "start_time": "2023-05-30T13:38:09.071388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_one_hot(label):\n",
    "    label = int(label)\n",
    "    t = np.zeros(6)\n",
    "    t[label] = 1\n",
    "    return torch.tensor(t).float()\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dir_path, params, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.files = os.listdir(dir_path)\n",
    "        self.transform=transform\n",
    "        self.params=params\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path=self.dir_path+'/'+self.files[idx]\n",
    "        machine_id=path.split('/')[-1].split('_')[-2]\n",
    "        label_path=path.split('/')[-1].split('_')[0]\n",
    "        \n",
    "        if label_path == \"normal\":\n",
    "            anomaly_label = 1\n",
    "        elif label_path == \"anomaly\":\n",
    "            anomaly_label = 0\n",
    "        else:\n",
    "            anomaly_label = 20\n",
    "            \n",
    "        audio, sr=load(path)\n",
    "        \n",
    "        mel_spectrogram= MelSpectrogram(\n",
    "                            sample_rate=sr,\n",
    "                            n_fft=params['n_fft'],\n",
    "                            hop_length=params['hop_len'],\n",
    "                            power=2.0\n",
    "                        )\n",
    "        \n",
    "        mel_spectr=mel_spectrogram(audio)\n",
    "\n",
    "        #spectrogram = Spectrogram(n_fft=446, win_length=446, hop_length=223)\n",
    "        #spectr=spectrogram(audio)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            audio=transform(audio)\n",
    "        \n",
    "        return audio, mel_spectr, return_one_hot(machine_id), anomaly_label, self.files[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79b6fc1b",
   "metadata": {
    "_cell_guid": "a125984d-e31f-4542-8984-ca6a86e55b29",
    "_uuid": "ade22b2b-9989-4d79-9c39-7cf8cf14365d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:09.100248Z",
     "iopub.status.busy": "2023-05-30T13:38:09.099489Z",
     "iopub.status.idle": "2023-05-30T13:38:09.107145Z",
     "shell.execute_reply": "2023-05-30T13:38:09.106246Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015224,
     "end_time": "2023-05-30T13:38:09.109062",
     "exception": false,
     "start_time": "2023-05-30T13:38:09.093838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class TGramNet(nn.Module):\\n    def __init__(self, mel_bins,win_len, hop_len, num_layers=3, **kwargs):\\n        super(TGramNet, self).__init__()\\n        \\n        self.conv1d = nn.Conv1d(in_channels=1, out_channels=mel_bins, kernel_size=win_len, stride=hop_len, padding=win_len // 2, bias=False)\\n        self.conv_encoder = nn.Sequential(\\n            *[nn.Sequential(\\n                nn.LayerNorm(int(160000//hop_len)+1),\\n                nn.GELU(),\\n                nn.Conv1d(mel_bins, mel_bins, 3, 1, 1, bias=False)\\n            ) for _ in range(num_layers)]\\n        )\\n        \\n    def forward(self, x_w):\\n        x_w = self.conv1d(x_w)\\n        x_w = self.conv_encoder(x_w)\\n        return x_w\\n\\nclass STGramNet(nn.Module):\\n    def __init__(self, params):\\n        super(STGramNet, self).__init__()\\n        self.arcface = False\\n        # self.arcface = ArcMarginProduct(in_features=128, out_features=num_classes, m=m, s=s, sub=sub) if use_arcface else use_arcface\\n        self.tgramnet = TGramNet(**params)\\n        # self.classifier = MobileFaceNet(num_class=num_classes, bottleneck_setting=bottleneck_setting)\\n        #self.classifier = nn.Linear(1001, num_classes)\\n        self.classifier = convnext_tiny()\\n        self.classifier.features[0][0] = nn.Conv2d(2, 96, kernel_size=(4, 4), stride=(4, 4))\\n        self.classifier.classifier[2] = nn.Linear(768, 6)\\n        self.transform = transforms.Normalize((0.5, 0.5), (0.25, 0.25))\\n        \\n        \\n    def forward(self, x_wav, x_mel, label=None):\\n        x_t = self.tgramnet(x_wav).unsqueeze(1)\\n        x = torch.cat((x_mel, x_t), dim=1).to(device)\\n        x = self.transform(x)\\n        out = self.classifier(x)\\n        if self.arcface:\\n            out = self.arcface(feature, label)\\n        return out'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class TGramNet(nn.Module):\n",
    "    def __init__(self, mel_bins,win_len, hop_len, num_layers=3, **kwargs):\n",
    "        super(TGramNet, self).__init__()\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels=1, out_channels=mel_bins, kernel_size=win_len, stride=hop_len, padding=win_len // 2, bias=False)\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.LayerNorm(int(160000//hop_len)+1),\n",
    "                nn.GELU(),\n",
    "                nn.Conv1d(mel_bins, mel_bins, 3, 1, 1, bias=False)\n",
    "            ) for _ in range(num_layers)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_w):\n",
    "        x_w = self.conv1d(x_w)\n",
    "        x_w = self.conv_encoder(x_w)\n",
    "        return x_w\n",
    "\n",
    "class STGramNet(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(STGramNet, self).__init__()\n",
    "        self.arcface = False\n",
    "        # self.arcface = ArcMarginProduct(in_features=128, out_features=num_classes, m=m, s=s, sub=sub) if use_arcface else use_arcface\n",
    "        self.tgramnet = TGramNet(**params)\n",
    "        # self.classifier = MobileFaceNet(num_class=num_classes, bottleneck_setting=bottleneck_setting)\n",
    "        #self.classifier = nn.Linear(1001, num_classes)\n",
    "        self.classifier = convnext_tiny()\n",
    "        self.classifier.features[0][0] = nn.Conv2d(2, 96, kernel_size=(4, 4), stride=(4, 4))\n",
    "        self.classifier.classifier[2] = nn.Linear(768, 6)\n",
    "        self.transform = transforms.Normalize((0.5, 0.5), (0.25, 0.25))\n",
    "        \n",
    "        \n",
    "    def forward(self, x_wav, x_mel, label=None):\n",
    "        x_t = self.tgramnet(x_wav).unsqueeze(1)\n",
    "        x = torch.cat((x_mel, x_t), dim=1).to(device)\n",
    "        x = self.transform(x)\n",
    "        out = self.classifier(x)\n",
    "        if self.arcface:\n",
    "            out = self.arcface(feature, label)\n",
    "        return out\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b8717f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:09.120436Z",
     "iopub.status.busy": "2023-05-30T13:38:09.119803Z",
     "iopub.status.idle": "2023-05-30T13:38:09.126764Z",
     "shell.execute_reply": "2023-05-30T13:38:09.125967Z"
    },
    "papermill": {
     "duration": 0.014812,
     "end_time": "2023-05-30T13:38:09.128818",
     "exception": false,
     "start_time": "2023-05-30T13:38:09.114006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class ArcFace(nn.Module):\\n    def __init__(self, embed_size, num_classes, scale=64, margin=0.5, easy_margin=False, **kwargs):\\n        super().__init__()\\n        self.scale = scale\\n        self.margin = margin\\n        self.ce = nn.CrossEntropyLoss()\\n        self.weight = nn.Parameter(torch.FloatTensor(num_classes, embed_size))\\n        self.easy_margin = easy_margin\\n        self.cos_m = math.cos(margin)\\n        self.sin_m = math.sin(margin)\\n        self.th = math.cos(math.pi - margin)\\n        self.mm = math.sin(math.pi - margin) * margin\\n\\n        nn.init.xavier_uniform_(self.weight)\\n\\n    def forward(self, embedding: torch.Tensor, ground_truth):\\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\\n        cos_theta = F.linear(F.normalize(embedding), F.normalize(self.weight)).clamp(-1 + 1e-7, 1 - 1e-7)\\n        sin_theta = torch.sqrt((1.0 - torch.pow(cos_theta, 2)).clamp(-1 + 1e-7, 1 - 1e-7))\\n        phi = cos_theta * self.cos_m - sin_theta * self.sin_m\\n        if self.easy_margin:\\n            phi = torch.where(cos_theta > 0, phi, cos_theta)\\n        else:\\n            phi = torch.where(cos_theta > self.th, phi, cos_theta - self.mm)\\n        # --------------------------- convert label to one-hot ---------------------------\\n        one_hot = torch.zeros(cos_theta.size(), device='cuda')\\n        one_hot.scatter_(1, ground_truth.view(-1, 1).long(), 1)\\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\\n        output = (one_hot * phi) + (\\n                (1.0 - one_hot) * cos_theta)  # you can use torch.where if your torch.__version__ is 0.4\\n        output *= self.scale\\n\\n        loss = self.ce(output, ground_truth)\\n        return loss, output\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class ArcFace(nn.Module):\n",
    "    def __init__(self, embed_size, num_classes, scale=64, margin=0.5, easy_margin=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, embed_size))\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, embedding: torch.Tensor, ground_truth):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cos_theta = F.linear(F.normalize(embedding), F.normalize(self.weight)).clamp(-1 + 1e-7, 1 - 1e-7)\n",
    "        sin_theta = torch.sqrt((1.0 - torch.pow(cos_theta, 2)).clamp(-1 + 1e-7, 1 - 1e-7))\n",
    "        phi = cos_theta * self.cos_m - sin_theta * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cos_theta > 0, phi, cos_theta)\n",
    "        else:\n",
    "            phi = torch.where(cos_theta > self.th, phi, cos_theta - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        one_hot = torch.zeros(cos_theta.size(), device='cuda')\n",
    "        one_hot.scatter_(1, ground_truth.view(-1, 1).long(), 1)\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + (\n",
    "                (1.0 - one_hot) * cos_theta)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        output *= self.scale\n",
    "\n",
    "        loss = self.ce(output, ground_truth)\n",
    "        return loss, output\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80061267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:09.140817Z",
     "iopub.status.busy": "2023-05-30T13:38:09.140032Z",
     "iopub.status.idle": "2023-05-30T13:38:09.153261Z",
     "shell.execute_reply": "2023-05-30T13:38:09.152464Z"
    },
    "papermill": {
     "duration": 0.021233,
     "end_time": "2023-05-30T13:38:09.155194",
     "exception": false,
     "start_time": "2023-05-30T13:38:09.133961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TGramNet(nn.Module):\n",
    "    def __init__(self, mel_bins,win_len, hop_len, num_layers=3, **kwargs):\n",
    "        super(TGramNet, self).__init__()\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels=1, out_channels=mel_bins, kernel_size=win_len, stride=hop_len, padding=win_len // 2, bias=False)\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.LayerNorm(int(160000//hop_len)+1),\n",
    "                nn.GELU(),\n",
    "                nn.Conv1d(mel_bins, mel_bins, 3, 1, 1, bias=False)\n",
    "            ) for _ in range(num_layers)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_w):\n",
    "        x_w = self.conv1d(x_w)\n",
    "        x_w = self.conv_encoder(x_w)\n",
    "        return x_w\n",
    "\n",
    "class STGramNet(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(STGramNet, self).__init__()\n",
    "        self.arcface = False\n",
    "        # self.arcface = ArcMarginProduct(in_features=128, out_features=num_classes, m=m, s=s, sub=sub) if use_arcface else use_arcface\n",
    "        self.tgramnet = TGramNet(**params)\n",
    "        # self.classifier = MobileFaceNet(num_class=num_classes, bottleneck_setting=bottleneck_setting)\n",
    "        #self.classifier = nn.Linear(1001, num_classes)\n",
    "        self.t_resnet=resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        for p in self.t_resnet.parameters():\n",
    "            p.requires_grad = True\n",
    "        #self.t_resnet.fc=nn.Linear(in_features=2048, out_features=384, bias=True)\n",
    "        self.t_resnet.fc=nn.Linear(in_features=512, out_features=384, bias=True)\n",
    "        \n",
    "        self.s_resnet=resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        for p in self.s_resnet.parameters():\n",
    "            p.requires_grad = True\n",
    "        #self.s_resnet.fc=nn.Linear(in_features=2048, out_features=384, bias=True)\n",
    "        self.s_resnet.fc=nn.Linear(in_features=512, out_features=384, bias=True)\n",
    "        \n",
    "        self.fc=nn.Sequential(nn.Linear(in_features=768, out_features=70),\n",
    "                               nn.BatchNorm1d(70),\n",
    "                               nn.GELU(),\n",
    "                               nn.Linear(in_features=70, out_features=6))\n",
    "        \n",
    "    def forward(self, x_wav, x_mel, label=None):\n",
    "        x_t = self.tgramnet(x_wav).unsqueeze(1).repeat(1, 3, 1, 1)\n",
    "        \n",
    "        x_t = self.t_resnet(x_t)\n",
    "        x_mel = self.s_resnet(x_mel)\n",
    "        \n",
    "        x = torch.cat((x_mel, x_mel), dim=1).to(device) \n",
    "        \n",
    "        out = self.fc(x)\n",
    "        if self.arcface:\n",
    "            out = self.arcface(feature, label)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8769eb7f",
   "metadata": {
    "_cell_guid": "d9c40d33-77cd-4466-8940-5e7645cd6d9d",
    "_uuid": "2ab11d80-9e9e-4505-b01c-894efad2df2a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:09.166842Z",
     "iopub.status.busy": "2023-05-30T13:38:09.166568Z",
     "iopub.status.idle": "2023-05-30T13:38:13.060505Z",
     "shell.execute_reply": "2023-05-30T13:38:13.059544Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.902792,
     "end_time": "2023-05-30T13:38:13.063094",
     "exception": false,
     "start_time": "2023-05-30T13:38:09.160302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 243MB/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# net = convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "net = STGramNet(params)\n",
    "# for p in net.parameters():\n",
    "#     p.requires_grad = False\n",
    "# net.classifier[2] = nn.Linear(768, 6)\n",
    "# net.fc = torch.nn.Linear(net.fc.in_features, 6)\n",
    "\n",
    "net = net.to(device)\n",
    "dev_train_path = \"/kaggle/input/eurecom-aml-2023-challenge-2/dev_data/dev_data/slider/train\"\n",
    "dev_test_path = \"/kaggle/input/eurecom-aml-2023-challenge-2/dev_data/dev_data/slider/test\"\n",
    "eval_train_path = \"/kaggle/input/eurecom-aml-2023-challenge-2/eval_data/eval_data/slider/train\"\n",
    "eval_test_path = \"/kaggle/input/eurecom-aml-2023-challenge-2/eval_data/eval_data/slider/test\"\n",
    "\n",
    "# mel_dev_train_path = \"/kaggle/input/aml2-melspectrograms/MelSpectrogram/dev_train/\"\n",
    "# mel_dev_test_path = \"/kaggle/input/aml2-melspectrograms/MelSpectrogram/dev_test/\"\n",
    "# mel_eval_train_path = \"/kaggle/input/aml2-melspectrograms/MelSpectrogram/eval_train/\"\n",
    "# mel_eval_test_path = \"/kaggle/input/aml2-melspectrograms/MelSpectrogram/eval_test/\"    \n",
    "\n",
    "# dev_train_ds = AudioDataset(params, dev_train_path, eval_path=dev_train_path)\n",
    "# dev_test_ds = AudioDataset(params, dev_test_path)\n",
    "\n",
    "dev_train_ds = AudioDataset(dev_train_path, params)\n",
    "eval_train_ds = AudioDataset(eval_train_path, params)\n",
    "train_ds = ConcatDataset([dev_train_ds, eval_train_ds])\n",
    "#train_dl=DataLoader(eval_train_ds, batch_size=params[\"batch_size\"], shuffle=True, num_workers=2)\n",
    "train_dl = DataLoader(train_ds, batch_size=params[\"batch_size\"], shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "dev_test_ds = AudioDataset(dev_train_path, params)\n",
    "eval_test_ds = AudioDataset(eval_train_path, params)\n",
    "\n",
    "test_ds = ConcatDataset([dev_test_ds, eval_test_ds])\n",
    "test_dl = DataLoader(dev_test_ds, batch_size=params[\"batch_size\"], shuffle=True, num_workers=2)\n",
    "\n",
    "# dev_train_dl = DataLoader(dev_train_ds, batch_size=params[\"batch_size\"], shuffle=True, num_workers=1)\n",
    "# dev_test_dl = DataLoader(dev_test_ds, batch_size=params[\"batch_size\"], shuffle=True, num_workers=1)\n",
    "\n",
    "# net = STGramNet(params).to(device)\n",
    "# net_params = [net_params for net_params in net.parameters() if net_params not in net.resnet.parameters()] + [net.resnet.fc.parameters()]\n",
    "net_params = [\n",
    "    {'params': net.tgramnet.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "]\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "#criterion = ArcFace(params[\"batch_size\"], 6).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38bfe1b5",
   "metadata": {
    "_cell_guid": "ba77ec76-cc45-4d42-967b-cb0404dd0b36",
    "_uuid": "921a2a1a-bdd2-4200-ba4f-0fbbb83a4c7d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:13.077437Z",
     "iopub.status.busy": "2023-05-30T13:38:13.075842Z",
     "iopub.status.idle": "2023-05-30T13:38:13.081244Z",
     "shell.execute_reply": "2023-05-30T13:38:13.080438Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013989,
     "end_time": "2023-05-30T13:38:13.083119",
     "exception": false,
     "start_time": "2023-05-30T13:38:13.069130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create spectrogram dataset\n",
    "# mel_dev_train_path = f\"/kaggle/working/mel_dataset/dev_data/train/\"\n",
    "# mel_dev_test_path = f\"/kaggle/working/mel_dataset/dev_data/test/\"\n",
    "# mel_eval_train_path = f\"/kaggle/working/mel_dataset/eval_data/train/\"\n",
    "# mel_eval_test_path = f\"/kaggle/working/mel_dataset/eval_data/test/\"\n",
    "\n",
    "# for d in [mel_dev_train_path, mel_dev_test_path, mel_eval_train_path, mel_eval_test_path]:\n",
    "    # if not os.path.exists(d):\n",
    "        # os.makedirs(d)\n",
    "\n",
    "    # for audio, mel, _, _, idx, filename in tqdm(train_ds):\n",
    "        # torch.save(mel, f\"{d}/{filename[:-4]}.audiomel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f0e567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:13.095161Z",
     "iopub.status.busy": "2023-05-30T13:38:13.094904Z",
     "iopub.status.idle": "2023-05-30T13:38:13.100631Z",
     "shell.execute_reply": "2023-05-30T13:38:13.099841Z"
    },
    "papermill": {
     "duration": 0.013982,
     "end_time": "2023-05-30T13:38:13.102599",
     "exception": false,
     "start_time": "2023-05-30T13:38:13.088617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\\nnet = convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\\nfor param in net.parameters():\\n    param.requires_grad = False\\nnet.classifier[2] = nn.Linear(768, 6)\\nnet = net.to(device)\\noptimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\\ncriterion = torch.nn.CrossEntropyLoss()\\nnet.train()\\naudio, spectrogram, machine_id, label = next(iter(dev_train_dl))\\n\\noptimizer.zero_grad()\\nout = net(spectrogram.to(device))\\nloss = criterion(out, machine_id.to(device))\\n# loss.retain_grad()\\nloss.backward()\\n# print(loss.grad)\\nprint(list(net.parameters())[0][0])\\noptimizer.step()\\nprint(list(net.parameters())[0][0])\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "net.classifier[2] = nn.Linear(768, 6)\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "net.train()\n",
    "audio, spectrogram, machine_id, label = next(iter(dev_train_dl))\n",
    "\n",
    "optimizer.zero_grad()\n",
    "out = net(spectrogram.to(device))\n",
    "loss = criterion(out, machine_id.to(device))\n",
    "# loss.retain_grad()\n",
    "loss.backward()\n",
    "# print(loss.grad)\n",
    "print(list(net.parameters())[0][0])\n",
    "optimizer.step()\n",
    "print(list(net.parameters())[0][0])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d96705a",
   "metadata": {
    "_cell_guid": "ce7001c8-6eb0-44d7-b347-6a8bed9a86b7",
    "_uuid": "e9c41679-8257-4951-8f93-4c3fabd5804e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T13:38:13.115135Z",
     "iopub.status.busy": "2023-05-30T13:38:13.114624Z",
     "iopub.status.idle": "2023-05-30T13:44:44.353346Z",
     "shell.execute_reply": "2023-05-30T13:44:44.351873Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 391.24832,
     "end_time": "2023-05-30T13:44:44.356556",
     "exception": false,
     "start_time": "2023-05-30T13:38:13.108236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:56<00:00, 21.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1528166738492025\n",
      "epoch 2th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:41<00:00, 28.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5575147025821581\n",
      "epoch 3th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:41<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3618765070720061\n",
      "epoch 4th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:42<00:00, 27.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.282857549225102\n",
      "epoch 5th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:43<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24531535553561232\n",
      "epoch 6th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:41<00:00, 28.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18476859333881723\n",
      "epoch 7th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:41<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18392968223821216\n",
      "epoch 8th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:40<00:00, 29.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14646023504862382\n",
      "epoch 9th\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1185/1185 [00:42<00:00, 28.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1338337997517368\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "l = []\n",
    "for e in range(params[\"epochs\"]):\n",
    "    print(f\"epoch {e+1}th\")\n",
    "    epoch_loss = []\n",
    "    for audio, spectrogram, machine_id, _, filename in tqdm(train_dl, total=len(train_dl)):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(audio.to(device), spectrogram.to(device).repeat(1, 3, 1, 1))\n",
    "        loss = criterion(output, machine_id.to(device))\n",
    "#         output.retain_grad()\n",
    "        loss.backward()\n",
    "        # print(output.grad.mean())\n",
    "#         fc_grad = net.resnet.fc.grad.copy()\n",
    "#         net.resnet.grad = torch.zeros_like(net.resnet.grad).to(device).float()\n",
    "#         net.resnet.fc.grad = fc_grad\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    l.append(np.array(epoch_loss).mean())\n",
    "    print(np.array(epoch_loss).mean())\n",
    "        # break\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b79d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:44:44.856889Z",
     "iopub.status.busy": "2023-05-30T13:44:44.856486Z",
     "iopub.status.idle": "2023-05-30T13:44:45.179831Z",
     "shell.execute_reply": "2023-05-30T13:44:45.178762Z"
    },
    "papermill": {
     "duration": 0.586816,
     "end_time": "2023-05-30T13:44:45.182240",
     "exception": false,
     "start_time": "2023-05-30T13:44:44.595424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7a6379e31d20>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83404cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T13:44:45.742498Z",
     "iopub.status.busy": "2023-05-30T13:44:45.742124Z",
     "iopub.status.idle": "2023-05-30T13:45:01.178033Z",
     "shell.execute_reply": "2023-05-30T13:45:01.176728Z"
    },
    "papermill": {
     "duration": 15.713047,
     "end_time": "2023-05-30T13:45:01.179519",
     "exception": true,
     "start_time": "2023-05-30T13:44:45.466472",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "eval_test_ds = AudioDataset(eval_test_path, params)\n",
    "#eval_test_ds = AudioDataset(eval_test_path, params)\n",
    "\n",
    "# test_ds = ConcatDataset([dev_test_ds, eval_test_ds])\n",
    "test_dl = DataLoader(eval_test_ds, batch_size=32, shuffle=False)\n",
    "names = []\n",
    "scores = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (audio, spectrogram, machine_id, label, filename) in tqdm(enumerate(test_dl), total=len(test_dl)):\n",
    "        output = net.forward(audio.to(device), spectrogram.to(device).repeat(1, 3, 1, 1))\n",
    "        softmax = output.softmax(dim=1)\n",
    "        score = softmax[:, machine_id.to(device).argmax(dim=1)].diag()\n",
    "        prob = 1 - score\n",
    "        y_true.extend(label)\n",
    "        y_pred.extend(score.cpu().numpy())\n",
    "        names.extend(filename)\n",
    "        scores.extend(prob.cpu().detach().numpy())\n",
    "    \n",
    "submission_df = pd.DataFrame(names, columns=[\"file_name\"])\n",
    "submission_df[\"anomaly_score\"] = scores\n",
    "submission_df.to_csv(\"/kaggle/working/sample_submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 428.980315,
   "end_time": "2023-05-30T13:45:04.393301",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-30T13:37:55.412986",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
